<div align="center">

<br/>

<a href="../16_Vision_Language/README.md"><img src="https://img.shields.io/badge/â—€__VL Models-0f172a?style=for-the-badge&labelColor=1e293b" height="35"/></a>
&nbsp;&nbsp;&nbsp;&nbsp;
<a href="../README.md"><img src="https://img.shields.io/badge/ğŸ __HOME-FBBF24?style=for-the-badge&labelColor=0f172a" height="35"/></a>
&nbsp;&nbsp;&nbsp;&nbsp;
<a href="../18_Deployment_Systems/README.md"><img src="https://img.shields.io/badge/Deployment__â–¶-0f172a?style=for-the-badge&labelColor=1e293b" height="35"/></a>

<br/><br/>

---

<br/>

# ğŸ“¸ COMPUTATIONAL PHOTO

### ğŸŒ™ *Beyond the Camera*

<br/>

<img src="https://img.shields.io/badge/ğŸ“š__MODULE__17/20-FBBF24?style=for-the-badge&labelColor=0f172a" height="40"/>
&nbsp;&nbsp;
<img src="https://img.shields.io/badge/â±ï¸__2_HOURS-FBBF24?style=for-the-badge&labelColor=0f172a" height="40"/>
&nbsp;&nbsp;
<img src="https://img.shields.io/badge/ğŸ““__NOTEBOOK_READY-34D399?style=for-the-badge&labelColor=0f172a" height="40"/>

<br/><br/>

---

</div>

<br/>

## ğŸ¯ Key Concepts

| Technique | Problem | Solution | Application |
| :--- | :--- | :--- | :--- |
| **HDR** | Limited dynamic range | Multi-exposure fusion | Landscape, architecture |
| **Panorama** | Limited field of view | Image stitching | 360Â° photos |
| **Deblurring** | Motion/defocus blur | Deconvolution | Action photos |
| **Inpainting** | Missing regions | Fill from context | Object removal |
| **Super-resolution** | Low resolution | Upscaling | Enhance photos |

---

## ğŸ¨ Visual Overview

<div align="center">
<img src="./svg_figs/hdr_pipeline.svg" alt="HDR Pipeline" width="100%"/>
</div>

---

## ğŸ”¢ Mathematical Foundations

### 1. High Dynamic Range (HDR) Imaging

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CAMERA RESPONSE FUNCTION                           â”‚
â”‚                                                     â”‚
â”‚  Pixel value: Z = f(E Ã— Î”t)                         â”‚
â”‚                                                     â”‚
â”‚  Where:                                             â”‚
â”‚    E = scene irradiance (what we want)              â”‚
â”‚    Î”t = exposure time                               â”‚
â”‚    f = camera response function (non-linear)        â”‚
â”‚                                                     â”‚
â”‚  INVERSE: E = fâ»Â¹(Z) / Î”t                           â”‚
â”‚                                                     â”‚
â”‚  DEBEVEC'S METHOD                                   â”‚
â”‚                                                     â”‚
â”‚  g(Z) = ln(fâ»Â¹(Z)) = ln(E) + ln(Î”t)                 â”‚
â”‚                                                     â”‚
â”‚  Solve: min Î£áµ¢â±¼[g(Záµ¢â±¼) - ln(Eáµ¢) - ln(Î”tâ±¼)]Â²         â”‚
â”‚            + Î» Î£ g''(z)Â²  (smoothness)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Tone Mapping Operators

| Operator | Formula | Properties |
| :--- | :--- | :--- |
| **Gamma** | L_out = L_in^(1/Î³) | Simple, global |
| **Reinhard** | L_out = L / (1 + L) | Photographic, global |
| **Bilateral** | Local contrast preservation | Edge-aware |
| **Exposure Fusion** | Mertens method | No HDR assembly |

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REINHARD GLOBAL OPERATOR                           â”‚
â”‚                                                     â”‚
â”‚  L_white = max luminance to map to white            â”‚
â”‚                                                     â”‚
â”‚  L_out = L(1 + L/L_whiteÂ²) / (1 + L)                â”‚
â”‚                                                     â”‚
â”‚  LOCAL OPERATOR adds spatial adaptation             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Panorama Stitching

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PIPELINE                                           â”‚
â”‚                                                     â”‚
â”‚  1. Feature detection (SIFT, ORB)                   â”‚
â”‚  2. Feature matching (FLANN, brute force)           â”‚
â”‚  3. RANSAC for homography estimation                â”‚
â”‚  4. Image warping: I' = H Â· I                       â”‚
â”‚  5. Blending: seamless transition                   â”‚
â”‚                                                     â”‚
â”‚  HOMOGRAPHY (planar scene or rotation only)         â”‚
â”‚                                                     â”‚
â”‚  [x']   [hâ‚ hâ‚‚ hâ‚ƒ] [x]                              â”‚
â”‚  [y'] = [hâ‚„ hâ‚… hâ‚†] [y]                              â”‚
â”‚  [1 ]   [hâ‚‡ hâ‚ˆ hâ‚‰] [1]                              â”‚
â”‚                                                     â”‚
â”‚  8 DOF, need 4 point correspondences minimum        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Image Blending

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAPLACIAN PYRAMID BLENDING                         â”‚
â”‚                                                     â”‚
â”‚  1. Build Laplacian pyramid for each image          â”‚
â”‚     Láµ¢ = Gáµ¢ - expand(Gáµ¢â‚Šâ‚)                          â”‚
â”‚                                                     â”‚
â”‚  2. Build Gaussian pyramid for mask                 â”‚
â”‚     Máµ¢ = reduce(Máµ¢â‚‹â‚)                               â”‚
â”‚                                                     â”‚
â”‚  3. Blend at each level                             â”‚
â”‚     Báµ¢ = Máµ¢ Ã— L1áµ¢ + (1-Máµ¢) Ã— L2áµ¢                    â”‚
â”‚                                                     â”‚
â”‚  4. Reconstruct from blended pyramid                â”‚
â”‚     Result = collapse(B)                            â”‚
â”‚                                                     â”‚
â”‚  POISSON BLENDING (gradient domain)                 â”‚
â”‚  min âˆ«âˆ« |âˆ‡f - v|Â² dÎ©, subject to f|âˆ‚Î© = f*|âˆ‚Î©       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. Deblurring / Deconvolution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BLUR MODEL                                         â”‚
â”‚                                                     â”‚
â”‚  g = h * f + n                                      â”‚
â”‚                                                     â”‚
â”‚  Where:                                             â”‚
â”‚    g = blurred image                                â”‚
â”‚    f = sharp image (unknown)                        â”‚
â”‚    h = blur kernel (PSF)                            â”‚
â”‚    n = noise                                        â”‚
â”‚                                                     â”‚
â”‚  In frequency domain: G = H Â· F + N                 â”‚
â”‚                                                     â”‚
â”‚  WIENER FILTER                                      â”‚
â”‚                                                     â”‚
â”‚  FÌ‚ = (H* / (|H|Â² + 1/SNR)) Â· G                     â”‚
â”‚                                                     â”‚
â”‚  Balances inverse filtering vs noise amplification  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6. Super-Resolution

| Type | Method | Key Idea |
| :--- | :--- | :--- |
| **Single-image** | SRCNN, ESPCN | Learn upscaling CNN |
| **Multi-image** | Burst SR | Combine multiple frames |
| **GAN-based** | SRGAN, Real-ESRGAN | Perceptual loss |
| **Diffusion** | SR3, StableSR | Generative prior |

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PERCEPTUAL LOSS (SRGAN)                            â”‚
â”‚                                                     â”‚
â”‚  L = L_content + Î»_adv L_adversarial                â”‚
â”‚                                                     â”‚
â”‚  L_content = ||VGG(I_SR) - VGG(I_HR)||Â²             â”‚
â”‚  L_adversarial = -log(D(I_SR))                      â”‚
â”‚                                                     â”‚
â”‚  Encourages realistic textures, not just PSNR       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Algorithms

### Algorithm 1: HDR Merge (Debevec)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUT: Images {Zâ±¼} with exposure times {Î”tâ±¼}       â”‚
â”‚  OUTPUT: HDR radiance map E                         â”‚
â”‚                                                     â”‚
â”‚  1. Sample pixels across exposure range             â”‚
â”‚  2. Solve for response curve g(Z) using SVD         â”‚
â”‚     - Overconstrained linear system                 â”‚
â”‚     - Add smoothness constraint                     â”‚
â”‚  3. Compute radiance:                               â”‚
â”‚     ln(Eáµ¢) = (Î£â±¼ w(Záµ¢â±¼)[g(Záµ¢â±¼) - ln(Î”tâ±¼)]) /        â”‚
â”‚              (Î£â±¼ w(Záµ¢â±¼))                            â”‚
â”‚                                                     â”‚
â”‚  Weight function w(Z):                              â”‚
â”‚  - Low weight at 0 and 255 (clipped)                â”‚
â”‚  - High weight in middle (well-exposed)             â”‚
â”‚                                                     â”‚
â”‚  4. Apply tone mapping for display                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Algorithm 2: Panorama Stitching

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUT: Images Iâ‚, Iâ‚‚, ...                          â”‚
â”‚  OUTPUT: Panorama                                   â”‚
â”‚                                                     â”‚
â”‚  1. Detect features (SIFT/ORB) in all images        â”‚
â”‚  2. Match features between adjacent pairs           â”‚
â”‚  3. FOR each pair (Iâ‚, Iáµ¦):                         â”‚
â”‚     4. RANSAC to find homography H:                 â”‚
â”‚        a. Sample 4 random matches                   â”‚
â”‚        b. Compute H from 4 points                   â”‚
â”‚        c. Count inliers (matches fitting H)         â”‚
â”‚        d. Repeat, keep H with most inliers          â”‚
â”‚     5. Refine H using all inliers (least squares)   â”‚
â”‚  6. Warp all images to reference frame              â”‚
â”‚  7. Multi-band blending to merge                    â”‚
â”‚                                                     â”‚
â”‚  8. RETURN stitched panorama                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Algorithm 3: Poisson Image Editing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUT: Source region S, target image T, mask M     â”‚
â”‚  OUTPUT: Seamlessly blended result                  â”‚
â”‚                                                     â”‚
â”‚  1. Compute gradient field of source: v = âˆ‡S        â”‚
â”‚  2. Set up Poisson equation:                        â”‚
â”‚     âˆ‡Â²f = div(v) inside region                      â”‚
â”‚     f = T on boundary                               â”‚
â”‚  3. Discretize as linear system:                    â”‚
â”‚     For each pixel p inside M:                      â”‚
â”‚     4f(p) - Î£_qâˆˆN(p) f(q) = Î£_qâˆˆN(p) vâ‚š_q           â”‚
â”‚  4. Solve sparse linear system (conjugate gradient) â”‚
â”‚  5. Composite: result = blend(T, f, M)              â”‚
â”‚                                                     â”‚
â”‚  Result: Gradients from source, colors from target  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â“ Interview Questions & Answers

<details>
<summary><b>Q1: How does HDR imaging work?</b></summary>

**Answer:**

**Problem:** Cameras have limited dynamic range (~8-12 stops)

**Solution:**
1. Capture multiple exposures (bracket)
2. Recover camera response function
3. Merge into HDR radiance map
4. Tone map for display

**Key insight:** Different exposures capture different parts of scene luminance

**Challenges:**
- Ghost artifacts (moving objects)
- Alignment between exposures
- Noise in dark regions

</details>

<details>
<summary><b>Q2: What is the difference between global and local tone mapping?</b></summary>

**Answer:**

| Aspect | Global | Local |
| :--- | :--- | :--- |
| Operation | Same function for all pixels | Spatially varying |
| Detail | May lose local contrast | Preserves local contrast |
| Speed | Fast | Slower |
| Artifacts | None | Halos possible |
| Example | Reinhard, Gamma | Bilateral filter |

**Local operators** adapt to neighborhood â†’ more detail but risk halos

</details>

<details>
<summary><b>Q3: How does Laplacian pyramid blending work?</b></summary>

**Answer:**

**Idea:** Blend different frequencies at different scales

**Steps:**
1. Build Laplacian pyramids (band-pass) for images
2. Build Gaussian pyramid for mask (smooth transitions)
3. Blend each level: L_blend = mask Ã— L1 + (1-mask) Ã— L2
4. Collapse pyramid to get result

**Why it works:**
- Low frequencies blend over large area (smooth)
- High frequencies blend over small area (preserves edges)
- Result: seamless transition

</details>

<details>
<summary><b>Q4: What is Poisson blending and when to use it?</b></summary>

**Answer:**

**Concept:** Match gradients, not colors

**Use cases:**
- Object insertion with different lighting
- Texture transfer
- Seamless cloning

**Formula:** min âˆ«|âˆ‡f - âˆ‡source|Â², with f = target on boundary

**Result:** Source gradients + target colors = natural blend

**Limitation:** Entire region shifts to match boundary colors

</details>

<details>
<summary><b>Q5: How does deconvolution work for deblurring?</b></summary>

**Answer:**

**Model:** g = h * f (blur = kernel * sharp)

**Naive:** f = Fâ»Â¹(G/H) - unstable (noise amplification)

**Wiener filter:** FÌ‚ = H*/(|H|Â² + 1/SNR) Ã— G
- Regularizes near zeros of H
- Balances sharpness vs noise

**Blind deconvolution:** Estimate both h and f simultaneously

</details>

<details>
<summary><b>Q6: What is the difference between interpolation and super-resolution?</b></summary>

**Answer:**

| Aspect | Interpolation | Super-Resolution |
| :--- | :--- | :--- |
| Method | Mathematical (bilinear, bicubic) | Learning-based |
| Detail | No new information | Hallucinates details |
| Quality | Blurry at high upscale | Sharper, more realistic |
| Training | None | Needs LR-HR pairs |

**SR adds plausible high-frequency details** based on learned priors

</details>

<details>
<summary><b>Q7: How do you handle moving objects in HDR?</b></summary>

**Answer:**

**Problem:** Ghost artifacts from misalignment

**Solutions:**
1. **Alignment:** Optical flow / feature matching
2. **Reference selection:** Choose one exposure as reference
3. **Motion detection:** Identify moving regions
4. **Weighted merge:** Lower weight for inconsistent pixels
5. **Deep learning:** End-to-end HDR with motion handling

</details>

<details>
<summary><b>Q8: What is exposure fusion vs HDR?</b></summary>

**Answer:**

| Aspect | HDR + Tone Mapping | Exposure Fusion |
| :--- | :--- | :--- |
| Creates HDR | Yes | No |
| Needs response curve | Yes | No |
| Quality measures | Exposure, contrast, saturation | Same |
| Result | LDR from HDR | LDR directly |
| Artifacts | Tone mapping artifacts | Blending artifacts |

**Mertens' exposure fusion:** Weight by quality metrics, blend with Laplacian pyramid

</details>

---

## ğŸ“š Key Formulas Reference

| Formula | Description |
| :--- | :--- |
| g(Z) = ln(E) + ln(Î”t) | Camera response |
| L_out = L/(1+L) | Reinhard tone mapping |
| H: x' = Hx | Homography transformation |
| âˆ‡Â²f = div(v) | Poisson equation |
| FÌ‚ = H*G/(|H|Â² + 1/SNR) | Wiener deconvolution |


---

<br/>

<div align="center">

## ğŸ““ PRACTICE

<br/>

### ğŸš€ Click to Open Directly in Google Colab

<br/>

<a href="https://colab.research.google.com/github/USERNAME/computer_vision_complete/blob/main/17_Computational_Photography/colab_tutorial.ipynb">
<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" height="50"/>
</a>

<br/><br/>

> âš ï¸ **First time?** Push this repo to GitHub, then replace `USERNAME` in the link above with your GitHub username.

<br/>

**Or manually:** [ğŸ“¥ Download](./colab_tutorial.ipynb) â†’ [ğŸŒ Colab](https://colab.research.google.com) â†’ Upload

</div>

<br/>




---

<br/>

<div align="center">

| | | |
|:---|:---:|---:|
| **[â—€ VL Models](../16_Vision_Language/README.md)** | **[ğŸ  HOME](../README.md)** | **[Deployment â–¶](../18_Deployment_Systems/README.md)** |

<br/>

---

ğŸŒ™ Part of **[Computer Vision Complete](../README.md)** Â· Made with â¤ï¸

<br/>

</div>
