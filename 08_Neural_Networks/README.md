<div align="center">

<br/>

<a href="../07_Classical_ML/README.md"><img src="https://img.shields.io/badge/â—€__Classical ML-0f172a?style=for-the-badge&labelColor=1e293b" height="35"/></a>
&nbsp;&nbsp;&nbsp;&nbsp;
<a href="../README.md"><img src="https://img.shields.io/badge/ğŸ __HOME-A78BFA?style=for-the-badge&labelColor=0f172a" height="35"/></a>
&nbsp;&nbsp;&nbsp;&nbsp;
<a href="../09_CNN_Architectures/README.md"><img src="https://img.shields.io/badge/CNNs__â–¶-0f172a?style=for-the-badge&labelColor=1e293b" height="35"/></a>

<br/><br/>

---

<br/>

# ğŸ§  NEURAL NETWORKS

### ğŸŒ™ *Deep Learning Foundations*

<br/>

<img src="https://img.shields.io/badge/ğŸ“š__MODULE__08/20-A78BFA?style=for-the-badge&labelColor=0f172a" height="40"/>
&nbsp;&nbsp;
<img src="https://img.shields.io/badge/â±ï¸__2_HOURS-FBBF24?style=for-the-badge&labelColor=0f172a" height="40"/>
&nbsp;&nbsp;
<img src="https://img.shields.io/badge/ğŸ““__NOTEBOOK_READY-34D399?style=for-the-badge&labelColor=0f172a" height="40"/>

<br/><br/>

---

</div>

<br/>

## ğŸ¯ Key Concepts

| Concept | Formula | Description |
| :--- | :--- | :--- |
| **Perceptron** | y = Ïƒ(wáµ€x + b) | Single neuron, linear classifier |
| **Forward Pass** | aË¡ = Ïƒ(WË¡aË¡â»Â¹ + bË¡) | Layer-by-layer computation |
| **Loss Function** | L = -Î£ylog(Å·) | Cross-entropy for classification |
| **Gradient** | âˆ‚L/âˆ‚W = âˆ‚L/âˆ‚a Â· âˆ‚a/âˆ‚W | Chain rule application |
| **Update Rule** | W â† W - Î·âˆ‡L | Gradient descent step |

---

## ğŸ¨ Visual Overview

<div align="center">
<img src="./svg_figs/backpropagation.svg" alt="Backpropagation" width="100%"/>
</div>

---

## ğŸ”¢ Mathematical Foundations

### 1. Single Neuron (Perceptron)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PERCEPTRON                                         â”‚
â”‚                                                     â”‚
â”‚  z = Î£áµ¢ wáµ¢xáµ¢ + b = wáµ€x + b                          â”‚
â”‚                                                     â”‚
â”‚  y = Ïƒ(z)  where Ïƒ is activation function           â”‚
â”‚                                                     â”‚
â”‚  Decision boundary: wáµ€x + b = 0 (hyperplane)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Activation Functions

| Function | Formula | Derivative | Properties |
| :--- | :--- | :--- | :--- |
| **Sigmoid** | Ïƒ(x) = 1/(1+eâ»Ë£) | Ïƒ(x)(1-Ïƒ(x)) | Range [0,1], vanishing gradient |
| **Tanh** | tanh(x) = (eË£-eâ»Ë£)/(eË£+eâ»Ë£) | 1-tanhÂ²(x) | Range [-1,1], zero-centered |
| **ReLU** | max(0,x) | 0 if x<0, 1 if x>0 | No vanishing gradient, sparse |
| **Leaky ReLU** | max(Î±x, x) | Î± if x<0, 1 if x>0 | No dead neurons |
| **GELU** | xÂ·Î¦(x) | Complex | Smooth, used in Transformers |
| **Softmax** | eË£â±/Î£eË£Ê² | páµ¢(Î´áµ¢â±¼ - pâ±¼) | Multi-class probabilities |

### 3. Multi-Layer Perceptron (MLP)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FORWARD PROPAGATION                                â”‚
â”‚                                                     â”‚
â”‚  Layer l:                                           â”‚
â”‚    zË¡ = WË¡aË¡â»Â¹ + bË¡                                 â”‚
â”‚    aË¡ = Ïƒ(zË¡)                                       â”‚
â”‚                                                     â”‚
â”‚  Where:                                             â”‚
â”‚    WË¡ âˆˆ â„â¿Ë¡Ã—â¿Ë¡â»Â¹  (weight matrix)                   â”‚
â”‚    bË¡ âˆˆ â„â¿Ë¡       (bias vector)                     â”‚
â”‚    aË¡ âˆˆ â„â¿Ë¡       (activations)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Loss Functions

| Loss | Formula | Use Case |
| :--- | :--- | :--- |
| **MSE** | L = (1/n)Î£(y-Å·)Â² | Regression |
| **Cross-Entropy** | L = -Î£ylog(Å·) | Classification |
| **Binary CE** | L = -[ylog(Å·) + (1-y)log(1-Å·)] | Binary classification |
| **Hinge** | L = max(0, 1-yÂ·Å·) | SVM-like margin |

### 5. Backpropagation (Chain Rule)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BACKWARD PROPAGATION                               â”‚
â”‚                                                     â”‚
â”‚  Output layer L:                                    â”‚
â”‚    Î´á´¸ = âˆ‚L/âˆ‚aá´¸ âŠ™ Ïƒ'(zá´¸)                             â”‚
â”‚                                                     â”‚
â”‚  Hidden layer l:                                    â”‚
â”‚    Î´Ë¡ = (WË¡âºÂ¹)áµ€Î´Ë¡âºÂ¹ âŠ™ Ïƒ'(zË¡)                        â”‚
â”‚                                                     â”‚
â”‚  Gradients:                                         â”‚
â”‚    âˆ‚L/âˆ‚WË¡ = Î´Ë¡(aË¡â»Â¹)áµ€                               â”‚
â”‚    âˆ‚L/âˆ‚bË¡ = Î´Ë¡                                      â”‚
â”‚                                                     â”‚
â”‚  âŠ™ = element-wise multiplication                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6. Optimization Algorithms

| Optimizer | Update Rule | Properties |
| :--- | :--- | :--- |
| **SGD** | W â† W - Î·âˆ‡L | Simple, may oscillate |
| **Momentum** | v â† Î²v + âˆ‡L, W â† W - Î·v | Accelerates in consistent direction |
| **RMSprop** | s â† Ïs + (1-Ï)(âˆ‡L)Â², W â† W - Î·âˆ‡L/âˆš(s+Îµ) | Adaptive learning rate |
| **Adam** | m â† Î²â‚m + (1-Î²â‚)âˆ‡L, v â† Î²â‚‚v + (1-Î²â‚‚)(âˆ‡L)Â², W â† W - Î·mÌ‚/âˆš(vÌ‚+Îµ) | Combines momentum + RMSprop |

**Adam Details:**
```
mÌ‚ = m/(1-Î²â‚áµ—)  (bias correction for 1st moment)
vÌ‚ = v/(1-Î²â‚‚áµ—)  (bias correction for 2nd moment)
Default: Î²â‚=0.9, Î²â‚‚=0.999, Îµ=10â»â¸
```

### 7. Weight Initialization

| Method | Formula | Best For |
| :--- | :--- | :--- |
| **Xavier/Glorot** | W ~ U[-âˆš(6/(náµ¢â‚™+nâ‚’áµ¤â‚œ)), âˆš(6/(náµ¢â‚™+nâ‚’áµ¤â‚œ))] | Sigmoid, Tanh |
| **He/Kaiming** | W ~ N(0, 2/náµ¢â‚™) | ReLU |
| **LeCun** | W ~ N(0, 1/náµ¢â‚™) | SELU |

**Why?** Maintain variance across layers: Var(aË¡) â‰ˆ Var(aË¡â»Â¹)

### 8. Regularization Techniques

| Technique | Effect | Formula/Method |
| :--- | :--- | :--- |
| **L2 (Weight Decay)** | Penalize large weights | L' = L + Î»Î£wÂ² |
| **L1 (Lasso)** | Encourage sparsity | L' = L + Î»Î£\|w\| |
| **Dropout** | Random neuron dropping | p(keep) = 1-p, scale by 1/(1-p) |
| **Batch Norm** | Normalize activations | xÌ‚ = (x-Î¼)/Ïƒ, y = Î³xÌ‚+Î² |
| **Early Stopping** | Stop before overfit | Monitor validation loss |

---

## âš™ï¸ Algorithms

### Algorithm 1: Stochastic Gradient Descent (SGD)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUT: Training data {(xáµ¢, yáµ¢)}, learning rate Î·   â”‚
â”‚  OUTPUT: Trained weights W, b                       â”‚
â”‚                                                     â”‚
â”‚  1. Initialize W, b randomly                        â”‚
â”‚  2. FOR epoch = 1 to num_epochs:                    â”‚
â”‚     3. Shuffle training data                        â”‚
â”‚     4. FOR each mini-batch B:                       â”‚
â”‚        5. Forward: Å· = f(x; W, b)                   â”‚
â”‚        6. Compute loss: L = Loss(Å·, y)              â”‚
â”‚        7. Backward: compute âˆ‚L/âˆ‚W, âˆ‚L/âˆ‚b            â”‚
â”‚        8. Update: W â† W - Î·Â·âˆ‚L/âˆ‚W                   â”‚
â”‚                   b â† b - Î·Â·âˆ‚L/âˆ‚b                   â”‚
â”‚  9. RETURN W, b                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Algorithm 2: Backpropagation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUT: Network with L layers, input x, target y    â”‚
â”‚  OUTPUT: Gradients âˆ‚L/âˆ‚WË¡, âˆ‚L/âˆ‚bË¡ for all l         â”‚
â”‚                                                     â”‚
â”‚  FORWARD PASS:                                      â”‚
â”‚  1. aâ° = x                                          â”‚
â”‚  2. FOR l = 1 to L:                                 â”‚
â”‚     3. zË¡ = WË¡aË¡â»Â¹ + bË¡                             â”‚
â”‚     4. aË¡ = Ïƒ(zË¡)                                   â”‚
â”‚                                                     â”‚
â”‚  BACKWARD PASS:                                     â”‚
â”‚  5. Î´á´¸ = âˆ‡â‚L(aá´¸, y) âŠ™ Ïƒ'(zá´¸)                        â”‚
â”‚  6. FOR l = L-1 to 1:                               â”‚
â”‚     7. Î´Ë¡ = (WË¡âºÂ¹)áµ€Î´Ë¡âºÂ¹ âŠ™ Ïƒ'(zË¡)                    â”‚
â”‚                                                     â”‚
â”‚  COMPUTE GRADIENTS:                                 â”‚
â”‚  8. FOR l = 1 to L:                                 â”‚
â”‚     9. âˆ‚L/âˆ‚WË¡ = Î´Ë¡(aË¡â»Â¹)áµ€                           â”‚
â”‚    10. âˆ‚L/âˆ‚bË¡ = Î´Ë¡                                  â”‚
â”‚                                                     â”‚
â”‚  RETURN all gradients                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Algorithm 3: Dropout (Training)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUT: Activation a, dropout probability p         â”‚
â”‚  OUTPUT: Masked activation                          â”‚
â”‚                                                     â”‚
â”‚  TRAINING:                                          â”‚
â”‚  1. m ~ Bernoulli(1-p)  (mask of 0s and 1s)         â”‚
â”‚  2. Ã£ = a âŠ™ m           (apply mask)                â”‚
â”‚  3. Ã£ = Ã£ / (1-p)       (scale to maintain E[a])    â”‚
â”‚                                                     â”‚
â”‚  INFERENCE:                                         â”‚
â”‚  1. Use all neurons (no dropout)                    â”‚
â”‚  2. No scaling needed (inverted dropout)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â“ Interview Questions & Answers

<details>
<summary><b>Q1: Explain the vanishing gradient problem.</b></summary>

**Answer:**
In deep networks, gradients become exponentially small as they backpropagate:

- **Cause**: Chain rule multiplication: âˆ‚L/âˆ‚WÂ¹ = âˆ‚L/âˆ‚aá´¸ Ã— âˆ‚aá´¸/âˆ‚aá´¸â»Â¹ Ã— ... Ã— âˆ‚aÂ²/âˆ‚aÂ¹ Ã— âˆ‚aÂ¹/âˆ‚WÂ¹
- **Sigmoid**: max derivative = 0.25, so after n layers: 0.25â¿ â†’ 0
- **Effect**: Early layers learn very slowly or not at all

**Solutions:**
1. ReLU activation (gradient = 1 for x > 0)
2. Residual connections (skip connections)
3. Proper initialization (He/Xavier)
4. Batch normalization
5. LSTM/GRU for RNNs

</details>

<details>
<summary><b>Q2: Why ReLU over Sigmoid?</b></summary>

**Answer:**

| Aspect | ReLU | Sigmoid |
| :--- | :--- | :--- |
| Gradient | 0 or 1 (no saturation for x>0) | 0-0.25 (saturates) |
| Computation | max(0,x) - fast | exp() - slow |
| Sparsity | ~50% neurons inactive | All active |
| Zero-centered | No | No |
| Dead neurons | Possible (if x<0 always) | No |

**When to use Sigmoid:** Output layer for binary classification (probability)

</details>

<details>
<summary><b>Q3: What is batch normalization and why does it help?</b></summary>

**Answer:**

**What:**
1. Normalize: xÌ‚ = (x - Î¼_batch) / âˆš(ÏƒÂ²_batch + Îµ)
2. Scale & shift: y = Î³xÌ‚ + Î² (learnable parameters)

**Why it helps:**
- **Faster training**: Allows higher learning rates
- **Regularization**: Adds noise via mini-batch statistics
- **Reduces internal covariate shift**: Stabilizes layer inputs
- **Allows deeper networks**: Prevents gradient issues

**Training vs Inference:**
- Training: Use batch statistics (Î¼_batch, Ïƒ_batch)
- Inference: Use running average statistics

</details>

<details>
<summary><b>Q4: Compare SGD, Momentum, and Adam.</b></summary>

**Answer:**

| Optimizer | Pros | Cons | When to Use |
| :--- | :--- | :--- | :--- |
| **SGD** | Simple, good generalization | Slow, oscillates | Fine-tuning |
| **SGD+Momentum** | Faster, reduces oscillation | Still needs LR tuning | Most cases |
| **Adam** | Adaptive LR, works out-of-box | May generalize worse | Prototyping |
| **AdamW** | Proper weight decay | Slightly more complex | Transformers |

**Adam formula:**
- m_t = Î²â‚m_{t-1} + (1-Î²â‚)g_t  (1st moment)
- v_t = Î²â‚‚v_{t-1} + (1-Î²â‚‚)g_tÂ² (2nd moment)
- Î¸ = Î¸ - Î·Â·mÌ‚_t/(âˆšvÌ‚_t + Îµ)

</details>

<details>
<summary><b>Q5: How does dropout prevent overfitting?</b></summary>

**Answer:**

**Mechanism:**
1. Randomly drop neurons with probability p during training
2. Forces network to be redundant - no single neuron is essential
3. Ensemble effect: like training 2^n different networks

**Mathematics:**
- Training: a' = a Ã— mask / (1-p)
- Inference: use full network (no dropout)

**Key insight:** Prevents co-adaptation of neurons

**Typical values:** p = 0.2-0.5 (higher for larger layers)

</details>

<details>
<summary><b>Q6: Why is weight initialization important?</b></summary>

**Answer:**

**Problem:** Bad initialization â†’ vanishing/exploding gradients

**Xavier/Glorot:** For sigmoid/tanh
```
Var(W) = 2 / (n_in + n_out)
```

**He/Kaiming:** For ReLU
```
Var(W) = 2 / n_in
```

**Goal:** Keep variance constant across layers
- Var(aË¡) â‰ˆ Var(aË¡â»Â¹)
- Var(âˆ‚L/âˆ‚aË¡) â‰ˆ Var(âˆ‚L/âˆ‚aË¡âºÂ¹)

</details>

<details>
<summary><b>Q7: What is the difference between L1 and L2 regularization?</b></summary>

**Answer:**

| Aspect | L1 (Lasso) | L2 (Ridge) |
| :--- | :--- | :--- |
| Penalty | Î»Î£\|w\| | Î»Î£wÂ² |
| Gradient | Â±Î» (constant) | 2Î»w (proportional) |
| Effect | Sparse weights (some = 0) | Small weights (none = 0) |
| Feature selection | Yes | No |
| Solution | Not differentiable at 0 | Smooth |

**L2 in optimizers:** Called "weight decay" - W â† W(1-Î»Î·) - Î·âˆ‡L

</details>

<details>
<summary><b>Q8: Explain the universal approximation theorem.</b></summary>

**Answer:**

**Theorem:** A neural network with one hidden layer of sufficient width can approximate any continuous function on compact subsets of â„â¿.

**Implications:**
- MLPs are theoretically powerful
- Width matters more than depth (in theory)
- BUT: may need exponentially many neurons

**Practice:**
- Deeper networks are more efficient
- Need proper training (optimization matters)
- Doesn't guarantee we can FIND the approximation

</details>

---

## ğŸ“š Key Formulas Reference

| Formula | Description |
| :--- | :--- |
| y = Ïƒ(Wx + b) | Neuron output |
| L = -Î£ylog(Å·) | Cross-entropy loss |
| âˆ‚L/âˆ‚W = Î´Â·aáµ€ | Weight gradient |
| Î´Ë¡ = (WË¡âºÂ¹)áµ€Î´Ë¡âºÂ¹ âŠ™ Ïƒ'(zË¡) | Error backpropagation |
| W â† W - Î·âˆ‡L | SGD update |
| m = Î²â‚m + (1-Î²â‚)âˆ‡L | Adam 1st moment |
| Var(W) = 2/n_in | He initialization |


---

<br/>

<div align="center">

## ğŸ““ PRACTICE

<br/>

### ğŸš€ Click to Open Directly in Google Colab

<br/>

<a href="https://colab.research.google.com/github/USERNAME/computer_vision_complete/blob/main/08_Neural_Networks/colab_tutorial.ipynb">
<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" height="50"/>
</a>

<br/><br/>

> âš ï¸ **First time?** Push this repo to GitHub, then replace `USERNAME` in the link above with your GitHub username.

<br/>

**Or manually:** [ğŸ“¥ Download](./colab_tutorial.ipynb) â†’ [ğŸŒ Colab](https://colab.research.google.com) â†’ Upload

</div>

<br/>




---

<br/>

<div align="center">

| | | |
|:---|:---:|---:|
| **[â—€ Classical ML](../07_Classical_ML/README.md)** | **[ğŸ  HOME](../README.md)** | **[CNNs â–¶](../09_CNN_Architectures/README.md)** |

<br/>

---

ğŸŒ™ Part of **[Computer Vision Complete](../README.md)** Â· Made with â¤ï¸

<br/>

</div>
