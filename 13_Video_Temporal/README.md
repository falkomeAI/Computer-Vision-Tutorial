<div align="center">

# ğŸ¬ Video & Temporal Vision

### *Optical Flow, Action Recognition, Tracking*

| Level | Time | Prerequisites |
|:-----:|:----:|:-------------:|
| ğŸŸ  Intermediate-Advanced | 3 hours | CNNs, Image Processing |

</div>

---

**Navigation:** [â† Self-Supervised](../12_Self_Supervised/) | [ğŸ  Home](../README.md) | [3D Vision â†’](../14_3D_Vision/)

---

## ğŸ“– Table of Contents
- [Key Concepts](#-key-concepts)
- [Mathematical Foundations](#-mathematical-foundations)
- [Algorithms](#-algorithms)
- [Visual Overview](#-visual-overview)
- [Interview Q&A](#-interview-questions--answers)

---

## ğŸ¯ Key Concepts

| Task | Input | Output | Key Methods |
|:-----|:------|:-------|:------------|
| **Optical Flow** | Frame t, Frame t+1 | Motion vectors (u,v) | Lucas-Kanade, RAFT |
| **Action Recognition** | Video clip | Action class | 3D CNN, Video Transformer |
| **Object Tracking** | Video + detection | Trajectories | SORT, DeepSORT |
| **Video Segmentation** | Video | Per-frame masks | SAM 2, XMem |

---

## ğŸ¨ Visual Overview

<div align="center">
<img src="./svg_figs/optical_flow.svg" alt="Optical Flow" width="100%"/>
</div>

---

## ğŸ”¢ Mathematical Foundations

### 1. Optical Flow Constraint Equation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BRIGHTNESS CONSTANCY ASSUMPTION                    â”‚
â”‚                                                     â”‚
â”‚  I(x, y, t) = I(x+u, y+v, t+1)                     â”‚
â”‚                                                     â”‚
â”‚  Taylor expansion:                                  â”‚
â”‚  I(x+u, y+v, t+1) â‰ˆ I + Iâ‚“u + Iáµ§v + Iâ‚œ            â”‚
â”‚                                                     â”‚
â”‚  OPTICAL FLOW EQUATION:                             â”‚
â”‚                                                     â”‚
â”‚  Iâ‚“u + Iáµ§v + Iâ‚œ = 0                                â”‚
â”‚                                                     â”‚
â”‚  Or: âˆ‡I Â· [u,v]áµ€ + Iâ‚œ = 0                          â”‚
â”‚                                                     â”‚
â”‚  Problem: 1 equation, 2 unknowns (aperture problem) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Lucas-Kanade Method

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ASSUMPTION: Flow is constant in local window       â”‚
â”‚                                                     â”‚
â”‚  For n pixels in window:                            â”‚
â”‚  [Iâ‚“â‚ Iáµ§â‚]   [u]   [-Iâ‚œâ‚]                          â”‚
â”‚  [Iâ‚“â‚‚ Iáµ§â‚‚]   [v] = [-Iâ‚œâ‚‚]                          â”‚
â”‚  [...  ...]         [...]                           â”‚
â”‚  [Iâ‚“â‚™ Iáµ§â‚™]         [-Iâ‚œâ‚™]                          â”‚
â”‚                                                     â”‚
â”‚       A      Â·  d  =   b                            â”‚
â”‚                                                     â”‚
â”‚  Least squares solution:                            â”‚
â”‚  d = (Aáµ€A)â»Â¹Aáµ€b                                    â”‚
â”‚                                                     â”‚
â”‚  Aáµ€A = [Î£Iâ‚“Â²   Î£Iâ‚“Iáµ§]  = Structure tensor M        â”‚
â”‚        [Î£Iâ‚“Iáµ§  Î£Iáµ§Â² ]                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Solvability:** Need Aáµ€A to be invertible â†’ corner points work best

### 3. Horn-Schunck Method (Dense Flow)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GLOBAL ENERGY MINIMIZATION                         â”‚
â”‚                                                     â”‚
â”‚  E = âˆ«âˆ« [(Iâ‚“u + Iáµ§v + Iâ‚œ)Â² + Î±Â²(|âˆ‡u|Â² + |âˆ‡v|Â²)] dxdyâ”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          Data term            Smoothness term       â”‚
â”‚                                                     â”‚
â”‚  Î± controls smoothness vs data fidelity             â”‚
â”‚  Large Î± â†’ smoother flow                            â”‚
â”‚                                                     â”‚
â”‚  Solved via Euler-Lagrange equations               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Multi-Scale Pyramid

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COARSE-TO-FINE ESTIMATION                          â”‚
â”‚                                                     â”‚
â”‚  Problem: Large motions violate linearization       â”‚
â”‚                                                     â”‚
â”‚  Solution:                                          â”‚
â”‚  1. Build image pyramid (downsample)                â”‚
â”‚  2. Compute flow at coarsest level                  â”‚
â”‚  3. Warp image, compute residual flow               â”‚
â”‚  4. Upsample and refine at next level               â”‚
â”‚  5. Repeat until finest level                       â”‚
â”‚                                                     â”‚
â”‚  Level L:  I_L â”€â”€â”€â”€â†’ Flow_L                        â”‚
â”‚              â†“         â†“                            â”‚
â”‚  Level L-1: I_{L-1} â†’ Warp â†’ Residual â†’ Flow_{L-1} â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. Action Recognition Formulations

| Approach | Representation | Formula |
|:---------|:---------------|:--------|
| **Two-Stream** | RGB + Flow | P = f_rgb + f_flow |
| **3D CNN** | Spatio-temporal | y = C3D(V[t-k:t+k]) |
| **LSTM** | Sequential features | hâ‚œ = LSTM(CNN(Iâ‚œ), hâ‚œâ‚‹â‚) |
| **Transformer** | Patch tokens | y = ViViT([CLS] + patches) |

### 6. Object Tracking - State Estimation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KALMAN FILTER (Linear Motion Model)                â”‚
â”‚                                                     â”‚
â”‚  State: x = [x, y, w, h, áº‹, áº, áº‡, á¸£]áµ€              â”‚
â”‚                                                     â”‚
â”‚  Predict:                                           â”‚
â”‚    xÌ‚â‚–|â‚–â‚‹â‚ = Fxâ‚–â‚‹â‚                                  â”‚
â”‚    Pâ‚–|â‚–â‚‹â‚ = FPâ‚–â‚‹â‚Fáµ€ + Q                            â”‚
â”‚                                                     â”‚
â”‚  Update:                                            â”‚
â”‚    K = Pâ‚–|â‚–â‚‹â‚Háµ€(HPâ‚–|â‚–â‚‹â‚Háµ€ + R)â»Â¹                  â”‚
â”‚    xÌ‚â‚– = xÌ‚â‚–|â‚–â‚‹â‚ + K(zâ‚– - HxÌ‚â‚–|â‚–â‚‹â‚)                  â”‚
â”‚    Pâ‚– = (I - KH)Pâ‚–|â‚–â‚‹â‚                             â”‚
â”‚                                                     â”‚
â”‚  F: motion model, H: observation model              â”‚
â”‚  Q: process noise, R: measurement noise             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7. Data Association (Hungarian Algorithm)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COST MATRIX                                        â”‚
â”‚                                                     â”‚
â”‚  C[i,j] = distance(track_i, detection_j)           â”‚
â”‚                                                     â”‚
â”‚  Common distances:                                  â”‚
â”‚  - IoU: 1 - IoU(bbox_track, bbox_det)              â”‚
â”‚  - Euclidean: ||center_track - center_det||        â”‚
â”‚  - Mahalanobis: (x-Î¼)áµ€Î£â»Â¹(x-Î¼) (uses Kalman cov)  â”‚
â”‚  - Cosine: 1 - cosine(appearance_emb)              â”‚
â”‚                                                     â”‚
â”‚  Hungarian algorithm finds optimal assignment       â”‚
â”‚  Complexity: O(nÂ³)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Algorithms

### Algorithm 1: Lucas-Kanade Optical Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUT: Image Iâ‚, Iâ‚‚, window size w                â”‚
â”‚  OUTPUT: Flow field (u, v)                         â”‚
â”‚                                                     â”‚
â”‚  1. Compute gradients: Iâ‚“, Iáµ§, Iâ‚œ                  â”‚
â”‚  2. FOR each pixel (x, y):                          â”‚
â”‚     3. Extract window W centered at (x,y)           â”‚
â”‚     4. Build A = [Iâ‚“, Iáµ§] for pixels in W          â”‚
â”‚     5. Build b = -Iâ‚œ for pixels in W               â”‚
â”‚     6. Solve: [u,v]áµ€ = (Aáµ€A)â»Â¹Aáµ€b                  â”‚
â”‚     7. Store flow(x,y) = (u, v)                     â”‚
â”‚  8. RETURN flow field                               â”‚
â”‚                                                     â”‚
â”‚  Note: Only compute at corner points for efficiency â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Algorithm 2: SORT (Simple Online Realtime Tracking)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUT: Detections per frame                        â”‚
â”‚  OUTPUT: Tracks with IDs                            â”‚
â”‚                                                     â”‚
â”‚  Initialize: tracks = []                            â”‚
â”‚  FOR each frame:                                    â”‚
â”‚    1. PREDICT: Kalman predict for all tracks       â”‚
â”‚    2. ASSOCIATE:                                    â”‚
â”‚       - Compute IoU(tracks, detections)             â”‚
â”‚       - Hungarian algorithm for assignment          â”‚
â”‚       - Threshold to reject bad matches             â”‚
â”‚    3. UPDATE:                                       â”‚
â”‚       - Matched: Kalman update with detection       â”‚
â”‚       - Unmatched track: increment miss count       â”‚
â”‚       - Unmatched detection: create new track       â”‚
â”‚    4. MANAGE:                                       â”‚
â”‚       - Delete tracks with miss > max_age           â”‚
â”‚       - Confirm tracks with hits > min_hits         â”‚
â”‚                                                     â”‚
â”‚  RETURN tracks                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Algorithm 3: Two-Stream Action Recognition

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUT: Video frames {Iâ‚, ..., Iâ‚œ}                 â”‚
â”‚  OUTPUT: Action class prediction                    â”‚
â”‚                                                     â”‚
â”‚  SPATIAL STREAM:                                    â”‚
â”‚  1. Sample single frame Iâ‚œ                          â”‚
â”‚  2. f_spatial = CNN_rgb(Iâ‚œ)                        â”‚
â”‚                                                     â”‚
â”‚  TEMPORAL STREAM:                                   â”‚
â”‚  3. Compute optical flow: {Fâ‚, ..., Fâ‚œâ‚‹â‚}          â”‚
â”‚  4. Stack L consecutive flows                       â”‚
â”‚  5. f_temporal = CNN_flow(stack)                   â”‚
â”‚                                                     â”‚
â”‚  FUSION:                                            â”‚
â”‚  6. Late fusion: P = softmax(f_spatial + f_temporal)â”‚
â”‚  7. OR Early fusion: concatenate features          â”‚
â”‚                                                     â”‚
â”‚  RETURN argmax(P)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â“ Interview Questions & Answers

<details>
<summary><b>Q1: Explain the aperture problem in optical flow.</b></summary>

**Answer:**

**Problem:** Looking through a small window, we can only measure motion perpendicular to edges, not along them.

**Mathematically:** Iâ‚“u + Iáµ§v + Iâ‚œ = 0 is one equation with two unknowns (u, v)

**Why corners work:** At corners, we have gradients in both x and y directions, making Aáµ€A invertible.

**Solutions:**
- Lucas-Kanade: Use larger window (local constraint)
- Horn-Schunck: Add global smoothness constraint
- Deep learning: Learn to resolve ambiguity

</details>

<details>
<summary><b>Q2: Lucas-Kanade vs Horn-Schunck?</b></summary>

**Answer:**

| Aspect | Lucas-Kanade | Horn-Schunck |
|:-------|:-------------|:-------------|
| Type | Local (sparse) | Global (dense) |
| Constraint | Constant flow in window | Smoothness |
| Result | Flow at corners | Flow everywhere |
| Speed | Fast | Slower |
| Large motion | Needs pyramid | Needs pyramid |
| Discontinuities | Handles well | Over-smooths |

</details>

<details>
<summary><b>Q3: How does RAFT improve optical flow?</b></summary>

**Answer:**

**RAFT (Recurrent All-Pairs Field Transforms):**

1. **All-pairs correlation:** Compute 4D correlation volume between all pixel pairs
2. **Iterative refinement:** Update flow estimate recurrently using GRU
3. **Multi-scale:** Correlation pyramid, not image pyramid

**Key innovations:**
- No coarse-to-fine warping
- Learns to update flow iteratively
- State-of-the-art accuracy

</details>

<details>
<summary><b>Q4: How does DeepSORT improve over SORT?</b></summary>

**Answer:**

**SORT:** Uses only IoU and Kalman filter

**DeepSORT adds:**
1. **Appearance features:** CNN embedding for each detection
2. **Cosine distance:** Match by appearance similarity
3. **Cascade matching:** Prioritize recent tracks
4. **Mahalanobis distance:** Use Kalman uncertainty

**Result:** Better handling of:
- Occlusions (re-identification)
- Camera motion
- Similar-looking objects

</details>

<details>
<summary><b>Q5: 3D CNN vs Two-Stream for action recognition?</b></summary>

**Answer:**

| Aspect | 3D CNN (C3D, I3D) | Two-Stream |
|:-------|:------------------|:-----------|
| Motion | Learned implicitly | Explicit (optical flow) |
| Computation | Higher (3D conv) | 2x models |
| Pretraining | Kinetics, etc. | ImageNet (2D) |
| Accuracy | Good | Competitive |
| Real-time | Harder | Possible |

**Modern approach:** Video Transformers (ViViT, TimeSformer) - patch-based, flexible

</details>

<details>
<summary><b>Q6: What is the difference between tracking and detection?</b></summary>

**Answer:**

| Aspect | Detection | Tracking |
|:-------|:----------|:---------|
| Input | Single frame | Video |
| Output | Bounding boxes | Trajectories with IDs |
| Temporal | No | Yes |
| Identity | No | Yes (same ID over time) |

**Tracking methods:**
- **Tracking-by-detection:** Detect + associate
- **Single-object tracking:** Given init box, follow
- **Multi-object tracking:** Multiple objects + IDs

</details>

<details>
<summary><b>Q7: Explain the Kalman filter for tracking.</b></summary>

**Answer:**

**State:** Position + velocity [x, y, w, h, áº‹, áº, áº‡, á¸£]

**Predict step:**
- Use motion model (constant velocity)
- Uncertainty increases

**Update step:**
- Get measurement (detection)
- Compute Kalman gain (trust measurement vs prediction)
- Update state and reduce uncertainty

**Key formulas:**
- Predict: xÌ‚ = Fx, P = FPFáµ€ + Q
- Update: K = PHáµ€(HPHáµ€ + R)â»Â¹

</details>

<details>
<summary><b>Q8: How to handle occlusion in tracking?</b></summary>

**Answer:**

**Strategies:**
1. **Keep predicting:** Use Kalman filter to predict trajectory
2. **Track management:** Don't delete immediately (max_age parameter)
3. **Re-identification:** Use appearance features to re-match
4. **Motion model:** Longer-term prediction with uncertainty

**DeepSORT approach:**
- Keep track alive for T frames without detection
- Use appearance embedding for re-identification
- Cascade matching: prefer recent matches

</details>

---

## ğŸ“š Key Formulas Reference

| Formula | Description |
|:--------|:------------|
| Iâ‚“u + Iáµ§v + Iâ‚œ = 0 | Optical flow constraint |
| d = (Aáµ€A)â»Â¹Aáµ€b | Lucas-Kanade solution |
| E = âˆ«(Data + Î±Smooth)dA | Horn-Schunck energy |
| xÌ‚ = Fx + Kz | Kalman filter update |
| C[i,j] = 1 - IoU(i,j) | SORT cost matrix |

---

## ğŸ““ Practice

See the Colab notebook: [`colab_tutorial.ipynb`](./colab_tutorial.ipynb)

---

<div align="center">

**[â† Self-Supervised](../12_Self_Supervised/) | [ğŸ  Home](../README.md) | [3D Vision â†’](../14_3D_Vision/)**

</div>
