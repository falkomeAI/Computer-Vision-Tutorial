{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udee1\ufe0f Ethics, Safety & Robustness\n",
        "\n",
        "**Topics:** Adversarial Attacks, Robustness, Fairness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "!pip install torch torchvision numpy matplotlib -q\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print('\u2705 Setup complete!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FGSM Attack\n",
        "def fgsm_attack(image, epsilon, gradient):\n",
        "    \"\"\"Fast Gradient Sign Method\"\"\"\n",
        "    # Get sign of gradient\n",
        "    sign_grad = gradient.sign()\n",
        "    # Add perturbation\n",
        "    perturbed = image + epsilon * sign_grad\n",
        "    # Clamp to valid range\n",
        "    perturbed = torch.clamp(perturbed, 0, 1)\n",
        "    return perturbed\n",
        "\n",
        "# Demo with synthetic data\n",
        "image = torch.rand(1, 1, 28, 28, requires_grad=True)\n",
        "gradient = torch.randn_like(image)  # Simulated gradient\n",
        "\n",
        "for eps in [0.0, 0.1, 0.3]:\n",
        "    perturbed = fgsm_attack(image, eps, gradient)\n",
        "    diff = (perturbed - image).abs().mean().item()\n",
        "    print(f'\u03b5={eps}: Mean perturbation = {diff:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Attack\n",
        "image = torch.rand(28, 28)\n",
        "gradient = torch.randn(28, 28)\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
        "axes[0].imshow(image.numpy(), cmap='gray')\n",
        "axes[0].set_title('Original')\n",
        "\n",
        "for i, eps in enumerate([0.1, 0.2, 0.3]):\n",
        "    perturbed = torch.clamp(image + eps * gradient.sign(), 0, 1)\n",
        "    axes[i+1].imshow(perturbed.numpy(), cmap='gray')\n",
        "    axes[i+1].set_title(f'\u03b5 = {eps}')\n",
        "\n",
        "for ax in axes: ax.axis('off')\n",
        "plt.suptitle('FGSM Attack with Increasing \u03b5')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PGD Attack (Iterative FGSM)\n",
        "def pgd_attack(image, epsilon, alpha, num_steps, gradient_fn):\n",
        "    \"\"\"Projected Gradient Descent Attack\"\"\"\n",
        "    perturbed = image.clone()\n",
        "    original = image.clone()\n",
        "    \n",
        "    for _ in range(num_steps):\n",
        "        # Get gradient (simulated here)\n",
        "        grad = gradient_fn(perturbed)\n",
        "        # FGSM step\n",
        "        perturbed = perturbed + alpha * grad.sign()\n",
        "        # Project back to epsilon ball\n",
        "        delta = torch.clamp(perturbed - original, -epsilon, epsilon)\n",
        "        perturbed = torch.clamp(original + delta, 0, 1)\n",
        "    \n",
        "    return perturbed\n",
        "\n",
        "# Demo\n",
        "image = torch.rand(28, 28)\n",
        "gradient_fn = lambda x: torch.randn_like(x)\n",
        "\n",
        "pgd_image = pgd_attack(image, epsilon=0.3, alpha=0.01, num_steps=40, gradient_fn=gradient_fn)\n",
        "print(f'PGD perturbation: max={abs(pgd_image - image).max():.3f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}