<div align="center">

# ğŸ¯ Vision Tasks

### *Detection, Segmentation & Beyond*

| Level | Time | Prerequisites |
|:-----:|:----:|:-------------:|
| ğŸŸ¡ Intermediate | 3 hours | CNNs, Deep Learning basics |

</div>

---

**Navigation:** [â† CNN Architectures](../09_CNN_Architectures/) | [ğŸ  Home](../README.md) | [Vision Transformers â†’](../11_Vision_Transformers/)

---

## ğŸ“– Table of Contents
- [Key Concepts](#-key-concepts)
- [Mathematical Foundations](#-mathematical-foundations)
- [Algorithms](#-algorithms)
- [Visual Overview](#-visual-overview)
- [Practice](#-practice)
- [Interview Q&A](#-interview-questions--answers)

---

## ğŸ¯ Key Concepts

| Task | Input | Output | Metric |
|:-----|:------|:-------|:-------|
| **Classification** | Image | Class label | Accuracy, Top-5 |
| **Detection** | Image | Boxes + labels | mAP@IoU |
| **Semantic Seg** | Image | Pixel-wise labels | mIoU |
| **Instance Seg** | Image | Masks + labels | AP |
| **Panoptic Seg** | Image | Things + Stuff | PQ |

---

## ğŸ¨ Visual Overview

<div align="center">
<img src="./svg_figs/detection_architectures.svg" alt="Detection Architectures" width="100%"/>
</div>

---

## ğŸ”¢ Mathematical Foundations

### 1. Intersection over Union (IoU)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  IoU = |A âˆ© B| / |A âˆª B|                           â”‚
â”‚                                                     â”‚
â”‚  For boxes:                                         â”‚
â”‚  A = (x1, y1, x2, y2)                              â”‚
â”‚  B = (x1', y1', x2', y2')                          â”‚
â”‚                                                     â”‚
â”‚  Intersection:                                      â”‚
â”‚  xi1 = max(x1, x1')                                â”‚
â”‚  yi1 = max(y1, y1')                                â”‚
â”‚  xi2 = min(x2, x2')                                â”‚
â”‚  yi2 = min(y2, y2')                                â”‚
â”‚  area_i = max(0, xi2-xi1) Ã— max(0, yi2-yi1)       â”‚
â”‚                                                     â”‚
â”‚  Union:                                             â”‚
â”‚  area_u = area_A + area_B - area_i                 â”‚
â”‚                                                     â”‚
â”‚  IoU = area_i / area_u                             â”‚
â”‚                                                     â”‚
â”‚  Range: [0, 1], higher is better                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Mean Average Precision (mAP)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PRECISION-RECALL CURVE                             â”‚
â”‚                                                     â”‚
â”‚  Precision = TP / (TP + FP)                        â”‚
â”‚  Recall = TP / (TP + FN)                           â”‚
â”‚                                                     â”‚
â”‚  AVERAGE PRECISION (per class)                     â”‚
â”‚                                                     â”‚
â”‚  AP = âˆ«â‚€Â¹ p(r) dr  â‰ˆ Î£ (ráµ¢ - ráµ¢â‚‹â‚) Ã— páµ¢â‚™â‚œâ‚‘áµ£â‚š     â”‚
â”‚                                                     â”‚
â”‚  11-point interpolation (PASCAL VOC):              â”‚
â”‚  AP = (1/11) Î£ max(p(r')) for r' â‰¥ r              â”‚
â”‚       râˆˆ{0,0.1,...,1}                              â”‚
â”‚                                                     â”‚
â”‚  MEAN AVERAGE PRECISION                            â”‚
â”‚                                                     â”‚
â”‚  mAP = (1/C) Î£ APc                                 â”‚
â”‚                                                     â”‚
â”‚  mAP@0.5: IoU threshold = 0.5                      â”‚
â”‚  mAP@0.5:0.95: average over IoU thresholds         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Non-Maximum Suppression (NMS)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUT: Boxes B, Scores S, IoU threshold Ï„         â”‚
â”‚  OUTPUT: Filtered boxes                             â”‚
â”‚                                                     â”‚
â”‚  1. Sort boxes by score (descending)               â”‚
â”‚  2. Select box with highest score â†’ D              â”‚
â”‚  3. Remove all boxes with IoU(box, D) > Ï„          â”‚
â”‚  4. Repeat until no boxes remain                   â”‚
â”‚                                                     â”‚
â”‚  SOFT-NMS (alternative):                           â”‚
â”‚  Instead of hard removal, decay scores:            â”‚
â”‚  sáµ¢ = sáµ¢ Ã— exp(-IoUÂ²/Ïƒ)                           â”‚
â”‚                                                     â”‚
â”‚  Typical Ï„ = 0.5 for detection                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Focal Loss (for class imbalance)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CROSS-ENTROPY LOSS                                 â”‚
â”‚                                                     â”‚
â”‚  CE(p, y) = -log(pâ‚œ)                               â”‚
â”‚  where pâ‚œ = p if y=1, else (1-p)                   â”‚
â”‚                                                     â”‚
â”‚  FOCAL LOSS                                         â”‚
â”‚                                                     â”‚
â”‚  FL(p, y) = -Î±â‚œ(1-pâ‚œ)áµ log(pâ‚œ)                     â”‚
â”‚                                                     â”‚
â”‚  (1-pâ‚œ)áµ: modulating factor                        â”‚
â”‚  - Easy examples (pâ‚œ â†’ 1): factor â†’ 0              â”‚
â”‚  - Hard examples (pâ‚œ â†’ 0): factor â†’ 1              â”‚
â”‚                                                     â”‚
â”‚  Typical: Î³ = 2, Î± = 0.25                          â”‚
â”‚                                                     â”‚
â”‚  Addresses: foreground-background imbalance        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. Segmentation Losses

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CROSS-ENTROPY (per pixel)                          â”‚
â”‚                                                     â”‚
â”‚  L = -(1/N) Î£áµ¢ Î£c yáµ¢c log(páµ¢c)                     â”‚
â”‚                                                     â”‚
â”‚  DICE LOSS                                          â”‚
â”‚                                                     â”‚
â”‚  Dice = 2|X âˆ© Y| / (|X| + |Y|)                     â”‚
â”‚  L_dice = 1 - Dice                                 â”‚
â”‚                                                     â”‚
â”‚  For soft predictions:                              â”‚
â”‚  L_dice = 1 - (2Î£páµ¢yáµ¢ + Îµ) / (Î£páµ¢ + Î£yáµ¢ + Îµ)      â”‚
â”‚                                                     â”‚
â”‚  IoU LOSS                                           â”‚
â”‚                                                     â”‚
â”‚  L_iou = 1 - IoU(pred, target)                     â”‚
â”‚                                                     â”‚
â”‚  Dice good for: imbalanced classes                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Algorithms

### Algorithm 1: Two-Stage Detection (Faster R-CNN)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. BACKBONE: Extract feature maps                 â”‚
â”‚     - ResNet/VGG â†’ multi-scale features           â”‚
â”‚                                                     â”‚
â”‚  2. REGION PROPOSAL NETWORK (RPN):                 â”‚
â”‚     - Slide 3Ã—3 window over feature map           â”‚
â”‚     - At each location: k anchors (scales/ratios) â”‚
â”‚     - Predict: objectness + box regression         â”‚
â”‚     - Output: ~2000 region proposals               â”‚
â”‚                                                     â”‚
â”‚  3. ROI POOLING/ALIGN:                             â”‚
â”‚     - Extract fixed-size features from proposals  â”‚
â”‚     - ROI Align: bilinear interpolation           â”‚
â”‚                                                     â”‚
â”‚  4. DETECTION HEAD:                                 â”‚
â”‚     - Classification: C+1 classes (+ background)  â”‚
â”‚     - Bounding box regression: 4C outputs         â”‚
â”‚                                                     â”‚
â”‚  5. POST-PROCESSING:                               â”‚
â”‚     - Apply NMS per class                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Algorithm 2: One-Stage Detection (YOLO)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. BACKBONE + NECK:                               â”‚
â”‚     - CSPDarknet + PANet (YOLOv4)                 â”‚
â”‚     - Multi-scale feature pyramids                â”‚
â”‚                                                     â”‚
â”‚  2. DETECTION HEAD (at each scale):                â”‚
â”‚     - Grid: SÃ—S cells                             â”‚
â”‚     - Each cell predicts B boxes:                 â”‚
â”‚       * 4 coordinates (x, y, w, h)                â”‚
â”‚       * 1 objectness score                        â”‚
â”‚       * C class probabilities                     â”‚
â”‚                                                     â”‚
â”‚  3. OUTPUT ENCODING:                               â”‚
â”‚     - (x, y): offset from cell corner             â”‚
â”‚     - (w, h): relative to anchor size             â”‚
â”‚                                                     â”‚
â”‚  4. LOSS FUNCTION:                                 â”‚
â”‚     L = Î»_coord Ã— L_box                           â”‚
â”‚       + Î»_obj Ã— L_obj                             â”‚
â”‚       + Î»_cls Ã— L_cls                             â”‚
â”‚                                                     â”‚
â”‚  5. NMS on all predictions                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Algorithm 3: Semantic Segmentation (DeepLab)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. ENCODER (with dilated/atrous convolutions):    â”‚
â”‚     - Preserve resolution with dilation           â”‚
â”‚     - Output stride = 8 or 16                     â”‚
â”‚                                                     â”‚
â”‚  2. ATROUS SPATIAL PYRAMID POOLING (ASPP):         â”‚
â”‚     - Parallel dilated convs at rates (6,12,18)   â”‚
â”‚     - 1Ã—1 conv (global features)                  â”‚
â”‚     - Concatenate all                             â”‚
â”‚                                                     â”‚
â”‚  3. DECODER:                                       â”‚
â”‚     - Upsample ASPP output                        â”‚
â”‚     - Concatenate with low-level features         â”‚
â”‚     - Refine boundaries                           â”‚
â”‚                                                     â”‚
â”‚  4. OUTPUT:                                        â”‚
â”‚     - 1Ã—1 conv â†’ C channels                       â”‚
â”‚     - Bilinear upsample to input resolution       â”‚
â”‚     - Softmax per pixel                           â”‚
â”‚                                                     â”‚
â”‚  Key: Dilated convs capture multi-scale context   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ““ Practice

See the Colab notebook for hands-on coding: [`colab_tutorial.ipynb`](./colab_tutorial.ipynb)

---

## â“ Interview Questions & Answers

<details>
<summary><b>Q1: One-stage vs two-stage detectors?</b></summary>

| Two-Stage (Faster R-CNN) | One-Stage (YOLO, SSD) |
|:-------------------------|:----------------------|
| Region proposals first | Direct prediction |
| Higher accuracy | Faster inference |
| Slower (~5 FPS) | Real-time (30+ FPS) |
| Better for small objects | May miss small objects |

**Modern:** One-stage closing accuracy gap (YOLOv5, FCOS)

</details>

<details>
<summary><b>Q2: What is Feature Pyramid Network (FPN)?</b></summary>

**Problem:** Objects at different scales

**Solution:** Multi-scale feature maps with top-down pathway

**Architecture:**
1. Bottom-up: standard backbone
2. Top-down: upsample + lateral connections
3. Output: pyramid of feature maps

**Benefit:** Strong features at all scales for detection

</details>

<details>
<summary><b>Q3: How does anchor-free detection work?</b></summary>

**Anchor-based:** Predefined box sizes/ratios
**Anchor-free:** Directly predict box coordinates

**Methods:**
- **FCOS:** Predict distance to edges at each point
- **CenterNet:** Predict center heatmap + size
- **CornerNet:** Predict top-left, bottom-right corners

**Advantage:** No anchor hyperparameter tuning

</details>

<details>
<summary><b>Q4: Explain dilated/atrous convolution.</b></summary>

**Standard conv:** Adjacent pixels
**Dilated conv:** Insert gaps (dilation rate r)

**Effective receptive field:** k' = k + (k-1)(r-1)

**Use in segmentation:**
- Large receptive field
- No resolution loss (no pooling)
- Multi-scale via different dilation rates (ASPP)

</details>

<details>
<summary><b>Q5: What is panoptic segmentation?</b></summary>

**Combines:**
- **Instance seg:** Things (countable: person, car)
- **Semantic seg:** Stuff (uncountable: sky, road)

**Metric:** Panoptic Quality (PQ) = SQ Ã— RQ
- SQ: Segmentation Quality (IoU of matched)
- RQ: Recognition Quality (like F1)

**Challenge:** Unified handling of things + stuff

</details>

<details>
<summary><b>Q6: How to handle class imbalance in detection?</b></summary>

**Problem:** Many more background than foreground

**Solutions:**
1. **Hard negative mining:** Sample hard negatives
2. **Focal loss:** Down-weight easy examples
3. **OHEM:** Online hard example mining
4. **Class weights:** Higher weight for rare classes

**Focal loss:** FL = -Î±â‚œ(1-pâ‚œ)áµ log(pâ‚œ), Î³=2 typical

</details>

---

## ğŸ“š Key Formulas Reference

| Formula | Description |
|:--------|:------------|
| IoU = \|Aâˆ©B\| / \|AâˆªB\| | Intersection over Union |
| mAP = (1/C)Î£APc | Mean Average Precision |
| FL = -Î±â‚œ(1-pâ‚œ)áµlog(pâ‚œ) | Focal Loss |
| Dice = 2\|Xâˆ©Y\|/(\|X\|+\|Y\|) | Dice coefficient |
| k' = k + (k-1)(r-1) | Dilated conv receptive field |

---

<div align="center">

**[â† CNN Architectures](../09_CNN_Architectures/) | [ğŸ  Home](../README.md) | [Vision Transformers â†’](../11_Vision_Transformers/)**

</div>
