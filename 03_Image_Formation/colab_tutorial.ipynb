{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üì∑ Image Formation\n",
        "\n",
        "### Understanding How Cameras See\n",
        "\n",
        "This notebook covers:\n",
        "- Pinhole camera model\n",
        "- Camera calibration\n",
        "- Lens distortion\n",
        "- Color spaces\n",
        "- Illumination models\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install opencv-python numpy matplotlib scipy -q\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Libraries installed and imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Pinhole Camera Model\n",
        "\n",
        "The pinhole camera model projects 3D world points to 2D image points:\n",
        "\n",
        "**Projection Equation:** `p = K[R|t]P`\n",
        "\n",
        "Where:\n",
        "- **K** (Intrinsic Matrix): Camera internal parameters (focal length, principal point)\n",
        "- **[R|t]** (Extrinsic Matrix): Camera pose (rotation and translation)\n",
        "- **P**: 3D world point\n",
        "- **p**: 2D image point\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple pinhole camera projection example\n",
        "\n",
        "def project_3d_to_2d(P_3d, K, R, t):\n",
        "    \"\"\"\n",
        "    Project 3D points to 2D using pinhole camera model\n",
        "    \n",
        "    Args:\n",
        "        P_3d: 3D points (N x 3)\n",
        "        K: Intrinsic matrix (3 x 3)\n",
        "        R: Rotation matrix (3 x 3)\n",
        "        t: Translation vector (3 x 1)\n",
        "    \n",
        "    Returns:\n",
        "        p_2d: 2D image points (N x 2)\n",
        "    \"\"\"\n",
        "    # Convert to homogeneous coordinates\n",
        "    P_homogeneous = np.hstack([P_3d, np.ones((P_3d.shape[0], 1))])\n",
        "    \n",
        "    # Create extrinsic matrix [R|t]\n",
        "    Rt = np.hstack([R, t])\n",
        "    \n",
        "    # Project: p = K[R|t]P\n",
        "    p_homogeneous = K @ Rt @ P_homogeneous.T\n",
        "    p_homogeneous = p_homogeneous.T\n",
        "    \n",
        "    # Convert back to Cartesian coordinates\n",
        "    p_2d = p_homogeneous[:, :2] / p_homogeneous[:, 2:3]\n",
        "    \n",
        "    return p_2d\n",
        "\n",
        "# Example: Define camera parameters\n",
        "fx, fy = 800, 800  # Focal length in pixels\n",
        "cx, cy = 320, 240  # Principal point\n",
        "\n",
        "# Intrinsic matrix K\n",
        "K = np.array([\n",
        "    [fx, 0, cx],\n",
        "    [0, fy, cy],\n",
        "    [0, 0, 1]\n",
        "])\n",
        "\n",
        "# Extrinsic parameters (camera looking at origin)\n",
        "R = np.eye(3)  # Identity rotation\n",
        "t = np.array([[0], [0], [5]])  # Camera 5 units back\n",
        "\n",
        "# Create some 3D points (a simple cube)\n",
        "cube_points = np.array([\n",
        "    [0, 0, 0], [1, 0, 0], [1, 1, 0], [0, 1, 0],  # Front face\n",
        "    [0, 0, -1], [1, 0, -1], [1, 1, -1], [0, 1, -1]  # Back face\n",
        "])\n",
        "\n",
        "# Project to 2D\n",
        "points_2d = project_3d_to_2d(cube_points, K, R, t)\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(points_2d[:, 0], points_2d[:, 1], s=100, c='red', marker='o')\n",
        "plt.plot([points_2d[0, 0], points_2d[1, 0]], [points_2d[0, 1], points_2d[1, 1]], 'b-')\n",
        "plt.plot([points_2d[1, 0], points_2d[2, 0]], [points_2d[1, 1], points_2d[2, 1]], 'b-')\n",
        "plt.plot([points_2d[2, 0], points_2d[3, 0]], [points_2d[2, 1], points_2d[3, 1]], 'b-')\n",
        "plt.plot([points_2d[3, 0], points_2d[0, 0]], [points_2d[3, 1], points_2d[0, 1]], 'b-')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title('Pinhole Camera Projection: 3D Cube ‚Üí 2D Image')\n",
        "plt.xlabel('u (pixels)')\n",
        "plt.ylabel('v (pixels)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úÖ Projected {len(cube_points)} 3D points to 2D\")\n",
        "print(f\"Image size: 640x480 pixels\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Camera Calibration\n",
        "\n",
        "Camera calibration estimates the intrinsic parameters (K) and distortion coefficients.\n",
        "\n",
        "**Zhang's Method:**\n",
        "1. Capture multiple images of a checkerboard\n",
        "2. Detect corner points\n",
        "3. Solve for K using homography constraints\n",
        "4. Refine with non-linear optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Camera Calibration Example\n",
        "# Note: This requires actual checkerboard images\n",
        "# Here we'll demonstrate the concept with synthetic data\n",
        "\n",
        "# Define checkerboard pattern\n",
        "checkerboard_size = (9, 6)  # Internal corners\n",
        "square_size = 1.0  # Size of each square in real units\n",
        "\n",
        "# Generate 3D object points (real-world coordinates)\n",
        "objp = np.zeros((checkerboard_size[0] * checkerboard_size[1], 3), np.float32)\n",
        "objp[:, :2] = np.mgrid[0:checkerboard_size[0], 0:checkerboard_size[1]].T.reshape(-1, 2)\n",
        "objp *= square_size\n",
        "\n",
        "# Simulate camera calibration process\n",
        "print(\"üìê Camera Calibration Process:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"1. Capture multiple images of checkerboard from different angles\")\n",
        "print(\"2. Detect corner points in each image\")\n",
        "print(\"3. Match 3D object points to 2D image points\")\n",
        "print(\"4. Solve for camera matrix K and distortion coefficients\")\n",
        "print(\"5. Refine using Levenberg-Marquardt optimization\")\n",
        "print()\n",
        "\n",
        "# Example calibration result (typical values)\n",
        "K_example = np.array([\n",
        "    [800, 0, 320],\n",
        "    [0, 800, 240],\n",
        "    [0, 0, 1]\n",
        "])\n",
        "\n",
        "dist_coeffs_example = np.array([-0.1, 0.05, 0, 0, 0])  # k1, k2, p1, p2, k3\n",
        "\n",
        "print(\"Example Calibration Results:\")\n",
        "print(f\"Intrinsic Matrix K:\\n{K_example}\")\n",
        "print(f\"\\nDistortion Coefficients: {dist_coeffs_example}\")\n",
        "print(f\"  k1, k2: Radial distortion\")\n",
        "print(f\"  p1, p2: Tangential distortion\")\n",
        "print(f\"  k3: Additional radial term\")\n",
        "\n",
        "# Visualize distortion effect\n",
        "def apply_distortion(x, y, k1, k2, p1, p2):\n",
        "    \"\"\"Apply radial and tangential distortion\"\"\"\n",
        "    r2 = x**2 + y**2\n",
        "    x_distorted = x * (1 + k1*r2 + k2*r2*r2) + 2*p1*x*y + p2*(r2 + 2*x**2)\n",
        "    y_distorted = y * (1 + k1*r2 + k2*r2*r2) + p1*(r2 + 2*y**2) + 2*p2*x*y\n",
        "    return x_distorted, y_distorted\n",
        "\n",
        "# Create grid of points\n",
        "x = np.linspace(-1, 1, 20)\n",
        "y = np.linspace(-1, 1, 20)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "\n",
        "# Apply distortion\n",
        "X_dist, Y_dist = apply_distortion(X, Y, dist_coeffs_example[0], \n",
        "                                   dist_coeffs_example[1],\n",
        "                                   dist_coeffs_example[2],\n",
        "                                   dist_coeffs_example[3])\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "axes[0].plot(X, Y, 'b-', alpha=0.3)\n",
        "axes[0].plot(X.T, Y.T, 'b-', alpha=0.3)\n",
        "axes[0].set_title('Original Grid (No Distortion)')\n",
        "axes[0].set_aspect('equal')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(X_dist, Y_dist, 'r-', alpha=0.3)\n",
        "axes[1].plot(X_dist.T, Y_dist.T, 'r-', alpha=0.3)\n",
        "axes[1].set_title('Distorted Grid (Barrel Distortion)')\n",
        "axes[1].set_aspect('equal')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Distortion visualization complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Color Space Conversions\n",
        "\n",
        "# Create a sample image with different colors\n",
        "height, width = 200, 400\n",
        "img_rgb = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "\n",
        "# Create color patches\n",
        "img_rgb[:100, :100] = [255, 0, 0]      # Red\n",
        "img_rgb[:100, 100:200] = [0, 255, 0]   # Green\n",
        "img_rgb[:100, 200:300] = [0, 0, 255]   # Blue\n",
        "img_rgb[:100, 300:] = [255, 255, 0]    # Yellow\n",
        "img_rgb[100:, :] = [128, 128, 128]     # Gray\n",
        "\n",
        "# Convert to different color spaces\n",
        "img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
        "img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
        "img_ycbcr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2YCR_CB)\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "axes[0, 0].imshow(img_rgb)\n",
        "axes[0, 0].set_title('RGB Color Space')\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "axes[0, 1].imshow(img_hsv)\n",
        "axes[0, 1].set_title('HSV Color Space')\n",
        "axes[0, 1].axis('off')\n",
        "\n",
        "axes[1, 0].imshow(img_lab)\n",
        "axes[1, 0].set_title('LAB Color Space')\n",
        "axes[1, 0].axis('off')\n",
        "\n",
        "axes[1, 1].imshow(img_ycbcr)\n",
        "axes[1, 1].set_title('YCbCr Color Space')\n",
        "axes[1, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show individual channels\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
        "\n",
        "# RGB channels\n",
        "axes[0, 0].imshow(img_rgb[:, :, 0], cmap='Reds')\n",
        "axes[0, 0].set_title('RGB - Red Channel')\n",
        "axes[0, 1].imshow(img_rgb[:, :, 1], cmap='Greens')\n",
        "axes[0, 1].set_title('RGB - Green Channel')\n",
        "axes[0, 2].imshow(img_rgb[:, :, 2], cmap='Blues')\n",
        "axes[0, 2].set_title('RGB - Blue Channel')\n",
        "\n",
        "# HSV channels\n",
        "axes[1, 0].imshow(img_hsv[:, :, 0], cmap='hsv')\n",
        "axes[1, 0].set_title('HSV - Hue')\n",
        "axes[1, 1].imshow(img_hsv[:, :, 1], cmap='gray')\n",
        "axes[1, 1].set_title('HSV - Saturation')\n",
        "axes[1, 2].imshow(img_hsv[:, :, 2], cmap='gray')\n",
        "axes[1, 2].set_title('HSV - Value')\n",
        "\n",
        "# LAB channels\n",
        "axes[2, 0].imshow(img_lab[:, :, 0], cmap='gray')\n",
        "axes[2, 0].set_title('LAB - L (Lightness)')\n",
        "axes[2, 1].imshow(img_lab[:, :, 1], cmap='RdYlGn')\n",
        "axes[2, 1].set_title('LAB - A (Green-Red)')\n",
        "axes[2, 2].imshow(img_lab[:, :, 2], cmap='RdYlBu')\n",
        "axes[2, 2].set_title('LAB - B (Blue-Yellow)')\n",
        "\n",
        "for ax in axes.flat:\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Color space conversions demonstrated!\")\n",
        "print(\"\\nKey Insights:\")\n",
        "print(\"- HSV: Hue separates color from brightness (useful for color-based segmentation)\")\n",
        "print(\"- LAB: Perceptually uniform (small changes = similar perceived difference)\")\n",
        "print(\"- YCbCr: Separates luminance (Y) from chrominance (Cb, Cr) - used in compression\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Gamma Correction\n",
        "\n",
        "Displays have non-linear response. Gamma correction compensates for this:\n",
        "\n",
        "**Encoding:** `V_out = V_in^(1/Œ≥)` where Œ≥ ‚âà 2.2  \n",
        "**Display:** `V_display = V_encoded^Œ≥`  \n",
        "**Result:** Perceived linear response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gamma Correction Demonstration\n",
        "\n",
        "def apply_gamma(image, gamma):\n",
        "    \"\"\"Apply gamma correction\"\"\"\n",
        "    inv_gamma = 1.0 / gamma\n",
        "    table = np.array([((i / 255.0) ** inv_gamma) * 255 \n",
        "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
        "    return cv2.LUT(image, table)\n",
        "\n",
        "# Create linear gradient\n",
        "linear_gradient = np.linspace(0, 255, 256).astype(np.uint8)\n",
        "linear_gradient = np.tile(linear_gradient, (100, 1))\n",
        "\n",
        "# Apply gamma correction (encoding)\n",
        "gamma = 2.2\n",
        "gamma_corrected = apply_gamma(linear_gradient, gamma)\n",
        "\n",
        "# Simulate display (decoding)\n",
        "display_output = apply_gamma(gamma_corrected, 1/gamma)\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "axes[0].imshow(linear_gradient, cmap='gray', aspect='auto')\n",
        "axes[0].set_title('Original Linear Gradient')\n",
        "axes[0].set_xlabel('Intensity')\n",
        "axes[0].set_ylabel('Row')\n",
        "\n",
        "axes[1].imshow(gamma_corrected, cmap='gray', aspect='auto')\n",
        "axes[1].set_title(f'After Gamma Encoding (Œ≥={gamma})')\n",
        "axes[1].set_xlabel('Encoded Intensity')\n",
        "\n",
        "axes[2].imshow(display_output, cmap='gray', aspect='auto')\n",
        "axes[2].set_title('After Display Decoding (Perceived Linear)')\n",
        "axes[2].set_xlabel('Perceived Intensity')\n",
        "\n",
        "for ax in axes:\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot intensity curves\n",
        "x = np.linspace(0, 1, 256)\n",
        "y_linear = x\n",
        "y_encoded = x ** (1/gamma)\n",
        "y_decoded = y_encoded ** gamma\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y_linear, 'b-', label='Original Linear', linewidth=2)\n",
        "plt.plot(x, y_encoded, 'r--', label=f'Encoded (Œ≥={gamma})', linewidth=2)\n",
        "plt.plot(x, y_decoded, 'g:', label='Decoded (Display)', linewidth=2)\n",
        "plt.xlabel('Input Intensity')\n",
        "plt.ylabel('Output Intensity')\n",
        "plt.title('Gamma Correction Curve')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Gamma correction demonstrated!\")\n",
        "print(f\"\\nStandard: sRGB uses Œ≥ = {gamma}\")\n",
        "print(\"Purpose: Compensate for non-linear display response\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Illumination Models\n",
        "\n",
        "### Lambertian Model (Diffuse Reflection)\n",
        "`I = kd √ó (N¬∑L)`\n",
        "\n",
        "Where:\n",
        "- **kd**: Diffuse reflectance coefficient\n",
        "- **N**: Surface normal\n",
        "- **L**: Light direction\n",
        "\n",
        "### Phong Model (Adds Specular)\n",
        "`I = ka + kd(N¬∑L) + ks(R¬∑V)‚Åø`\n",
        "\n",
        "Where:\n",
        "- **ka**: Ambient term\n",
        "- **ks**: Specular coefficient\n",
        "- **R**: Reflection vector\n",
        "- **V**: View direction\n",
        "- **n**: Shininess exponent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Illumination Models Visualization\n",
        "\n",
        "def lambertian_shading(normal, light_dir, kd):\n",
        "    \"\"\"Lambertian (diffuse) shading\"\"\"\n",
        "    cos_angle = np.clip(np.dot(normal, light_dir), 0, 1)\n",
        "    return kd * cos_angle\n",
        "\n",
        "def phong_shading(normal, light_dir, view_dir, ka, kd, ks, n):\n",
        "    \"\"\"Phong shading model\"\"\"\n",
        "    # Ambient\n",
        "    ambient = ka\n",
        "    \n",
        "    # Diffuse (Lambertian)\n",
        "    cos_angle = np.clip(np.dot(normal, light_dir), 0, 1)\n",
        "    diffuse = kd * cos_angle\n",
        "    \n",
        "    # Specular\n",
        "    reflect_dir = 2 * np.dot(normal, light_dir) * normal - light_dir\n",
        "    reflect_dir = reflect_dir / np.linalg.norm(reflect_dir)\n",
        "    specular = ks * (np.clip(np.dot(reflect_dir, view_dir), 0, 1) ** n)\n",
        "    \n",
        "    return ambient + diffuse + specular\n",
        "\n",
        "# Create a sphere surface\n",
        "size = 200\n",
        "x = np.linspace(-1, 1, size)\n",
        "y = np.linspace(-1, 1, size)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "Z = np.sqrt(np.maximum(1 - X**2 - Y**2, 0))\n",
        "\n",
        "# Surface normals\n",
        "normals = np.zeros((size, size, 3))\n",
        "normals[:, :, 0] = X\n",
        "normals[:, :, 1] = Y\n",
        "normals[:, :, 2] = Z\n",
        "normals = normals / (np.linalg.norm(normals, axis=2, keepdims=True) + 1e-8)\n",
        "\n",
        "# Light and view directions\n",
        "light_dir = np.array([0.5, 0.5, 1])\n",
        "light_dir = light_dir / np.linalg.norm(light_dir)\n",
        "view_dir = np.array([0, 0, 1])\n",
        "\n",
        "# Shading parameters\n",
        "ka, kd, ks = 0.1, 0.7, 0.2\n",
        "n = 32\n",
        "\n",
        "# Compute shading\n",
        "lambertian_img = np.zeros((size, size))\n",
        "phong_img = np.zeros((size, size))\n",
        "\n",
        "for i in range(size):\n",
        "    for j in range(size):\n",
        "        if Z[i, j] > 0:\n",
        "            normal = normals[i, j]\n",
        "            lambertian_img[i, j] = lambertian_shading(normal, light_dir, kd)\n",
        "            phong_img[i, j] = phong_shading(normal, light_dir, view_dir, ka, kd, ks, n)\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "im1 = axes[0].imshow(lambertian_img, cmap='gray', vmin=0, vmax=1)\n",
        "axes[0].set_title('Lambertian Shading (Diffuse Only)')\n",
        "axes[0].axis('off')\n",
        "plt.colorbar(im1, ax=axes[0])\n",
        "\n",
        "im2 = axes[1].imshow(phong_img, cmap='gray', vmin=0, vmax=1)\n",
        "axes[1].set_title('Phong Shading (Ambient + Diffuse + Specular)')\n",
        "axes[1].axis('off')\n",
        "plt.colorbar(im2, ax=axes[1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Illumination models demonstrated!\")\n",
        "print(\"\\nKey Differences:\")\n",
        "print(\"- Lambertian: Smooth, matte appearance (no highlights)\")\n",
        "print(\"- Phong: Adds specular highlights for shiny surfaces\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Summary\n",
        "\n",
        "In this notebook, we covered:\n",
        "\n",
        "1. **Pinhole Camera Model**: 3D ‚Üí 2D projection using `p = K[R|t]P`\n",
        "2. **Camera Calibration**: Estimating intrinsic parameters and distortion\n",
        "3. **Color Spaces**: RGB, HSV, LAB, YCbCr and their applications\n",
        "4. **Gamma Correction**: Compensating for non-linear display response\n",
        "5. **Illumination Models**: Lambertian and Phong shading\n",
        "\n",
        "### Key Takeaways:\n",
        "- Understanding image formation is crucial for computer vision\n",
        "- Camera calibration enables accurate 3D reconstruction\n",
        "- Color space choice depends on the task\n",
        "- Gamma correction ensures consistent appearance across displays\n",
        "- Illumination models help understand how light interacts with surfaces\n",
        "\n",
        "---\n",
        "\n",
        "**Next Steps:**\n",
        "- Try camera calibration with real checkerboard images\n",
        "- Experiment with color-based segmentation using HSV\n",
        "- Implement your own shading model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
